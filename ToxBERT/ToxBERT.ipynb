{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-14T14:16:47.310609Z",
     "iopub.status.busy": "2025-11-14T14:16:47.309871Z",
     "iopub.status.idle": "2025-11-14T14:16:47.314979Z",
     "shell.execute_reply": "2025-11-14T14:16:47.314340Z",
     "shell.execute_reply.started": "2025-11-14T14:16:47.310584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, hamming_loss, precision_recall_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:16:54.216911Z",
     "iopub.status.busy": "2025-11-14T14:16:54.216074Z",
     "iopub.status.idle": "2025-11-14T14:16:54.221528Z",
     "shell.execute_reply": "2025-11-14T14:16:54.220803Z",
     "shell.execute_reply.started": "2025-11-14T14:16:54.216877Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LOAD 3 DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:17:55.738426Z",
     "iopub.status.busy": "2025-11-14T14:17:55.737608Z",
     "iopub.status.idle": "2025-11-14T14:19:10.901583Z",
     "shell.execute_reply": "2025-11-14T14:19:10.900733Z",
     "shell.execute_reply.started": "2025-11-14T14:17:55.738398Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOADING DATASETS...\n",
      "Tox21: 8014 samples, 12 labels\n",
      "SIDER: 1427 samples, 27 labels\n",
      "DrugBank parsed: 12313 samples, 10 ADR labels\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLOADING DATASETS...\")\n",
    "\n",
    "# --- Tox21 ---\n",
    "TOX21_PATH = \"/kaggle/input/dataset/tox21.csv\"  # Attachment\n",
    "df_tox = pd.read_csv(TOX21_PATH)\n",
    "tox_labels = [\"NR-AR\",\"NR-AR-LBD\",\"NR-AhR\",\"NR-Aromatase\",\"NR-ER\",\"NR-ER-LBD\",\n",
    "              \"NR-PPAR-gamma\",\"SR-ARE\",\"SR-ATAD5\",\"SR-HSE\",\"SR-MMP\",\"SR-p53\"]\n",
    "# ensure these columns exist\n",
    "for c in tox_labels:\n",
    "    if c not in df_tox.columns:\n",
    "        df_tox[c] = 0\n",
    "df_tox[\"labels\"] = df_tox[tox_labels].fillna(0).astype(float).values.tolist()\n",
    "df_tox[\"dataset\"] = \"tox21\"\n",
    "print(f\"Tox21: {len(df_tox)} samples, 12 labels\")\n",
    "\n",
    "# --- SIDER ---\n",
    "SIDER_PATH = \"/kaggle/input/dataset/sider.csv\"  # Attachment\n",
    "df_sider = pd.read_csv(SIDER_PATH)\n",
    "# assume first column is molecule identifier, rest are labels\n",
    "sider_labels = df_sider.columns[1:].tolist()\n",
    "# convert NaN -> 0 and ensure numeric\n",
    "df_sider[sider_labels] = df_sider[sider_labels].fillna(0).astype(float)\n",
    "df_sider[\"labels\"] = df_sider[sider_labels].values.tolist()\n",
    "df_sider[\"dataset\"] = \"sider\"\n",
    "print(f\"SIDER: {len(df_sider)} samples, {len(sider_labels)} labels\")\n",
    "\n",
    "# --- DrugBank XML Parse ---\n",
    "DRUGBANK_PATH = \"/kaggle/input/dataset/drugbank_full_database.xml\"  # Attachment (if not present, you can use drugbank.csv instead)\n",
    "common_adrs = ['nausea', 'vomiting', 'headache', 'dizziness', 'fatigue',\n",
    "               'diarrhea', 'rash', 'liver injury', 'cardiotoxicity', 'hair loss']\n",
    "\n",
    "df_drug = pd.DataFrame()\n",
    "if os.path.exists(DRUGBANK_PATH):\n",
    "    try:\n",
    "        tree = ET.parse(DRUGBANK_PATH)\n",
    "        root = tree.getroot()\n",
    "        ns = {'db': 'http://www.drugbank.ca'}  # typical namespace; if your xml has none you can remove ns usage\n",
    "\n",
    "        data = []\n",
    "        # Try with namespace; if no results, try without ns\n",
    "        drugs = root.findall('db:drug', ns)\n",
    "        if len(drugs) == 0:\n",
    "            drugs = root.findall('drug')  # fallback to tag without ns\n",
    "\n",
    "        for drug in drugs:\n",
    "            # name (safe)\n",
    "            name_tag = drug.find('db:name', ns) if ns and drug.find('db:name', ns) is not None else drug.find('name')\n",
    "            name = name_tag.text.strip() if name_tag is not None and name_tag.text else None\n",
    "\n",
    "            # find SMILES robustly\n",
    "            smiles = None\n",
    "            # try paths with namespace first\n",
    "            props = drug.findall(\"db:calculated-properties/db:property\", ns) if ns else drug.findall(\"calculated-properties/property\")\n",
    "            if not props:\n",
    "                # fallback to property nodes without ns\n",
    "                props = drug.findall(\"calculated-properties/property\") or drug.findall(\"property\")\n",
    "\n",
    "            for prop in props:\n",
    "                kind_tag = prop.find('db:kind', ns) if ns and prop.find('db:kind', ns) is not None else prop.find('kind')\n",
    "                val_tag = prop.find('db:value', ns) if ns and prop.find('db:value', ns) is not None else prop.find('value')\n",
    "                if kind_tag is None or val_tag is None:\n",
    "                    continue\n",
    "                kind = kind_tag.text.strip().lower()\n",
    "                if kind == 'smiles':\n",
    "                    smiles = val_tag.text.strip()\n",
    "                    break\n",
    "            if not smiles:\n",
    "                continue\n",
    "\n",
    "            # ADR text from toxicity\n",
    "            toxicity_tag = drug.find('db:toxicity', ns) if ns and drug.find('db:toxicity', ns) is not None else drug.find('toxicity')\n",
    "            adr_text = toxicity_tag.text.strip() if (toxicity_tag is not None and toxicity_tag.text) else \"\"\n",
    "\n",
    "            adr_labels = [1.0 if adr in adr_text.lower() else 0.0 for adr in common_adrs]\n",
    "\n",
    "            data.append({'smiles': smiles, 'labels': adr_labels, 'dataset': 'drugbank', 'adr_text': adr_text, 'name': name})\n",
    "\n",
    "        df_drug = pd.DataFrame(data)\n",
    "        print(f\"DrugBank parsed: {len(df_drug)} samples, {len(common_adrs)} ADR labels\")\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing DrugBank XML:\", e)\n",
    "else:\n",
    "    # fallback in case user supplied a csv instead of XML\n",
    "    DRUGBANK_CSV = \"drugbank.csv\"\n",
    "    if os.path.exists(DRUGBANK_CSV):\n",
    "        df_drug = pd.read_csv(DRUGBANK_CSV)\n",
    "        # assume 'smiles' and ADR columns or provide ADR text\n",
    "        if 'smiles' in df_drug.columns:\n",
    "            if 'adr_text' in df_drug.columns:\n",
    "                df_drug['adr_text'] = df_drug['adr_text'].fillna(\"\")\n",
    "                df_drug['labels'] = df_drug['adr_text'].apply(lambda t: [1.0 if adr in str(t).lower() else 0.0 for adr in common_adrs])\n",
    "            else:\n",
    "                # if drugbank csv has explicit ADR columns\n",
    "                adr_cols = [c for c in df_drug.columns if c.lower() in common_adrs]\n",
    "                if adr_cols:\n",
    "                    df_drug[adr_cols] = df_drug[adr_cols].fillna(0).astype(float)\n",
    "                    df_drug['labels'] = df_drug[adr_cols].values.tolist()\n",
    "                else:\n",
    "                    # fallback: all zeros\n",
    "                    df_drug['labels'] = [[0.0]*len(common_adrs) for _ in range(len(df_drug))]\n",
    "        else:\n",
    "            df_drug = pd.DataFrame()  # couldn't parse fallback\n",
    "    if df_drug.empty:\n",
    "        print(\"No DrugBank data found (XML or drugbank.csv). DrugBank will be skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:19:10.903333Z",
     "iopub.status.busy": "2025-11-14T14:19:10.903134Z",
     "iopub.status.idle": "2025-11-14T14:19:10.911097Z",
     "shell.execute_reply": "2025-11-14T14:19:10.910339Z",
     "shell.execute_reply.started": "2025-11-14T14:19:10.903317Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles  \\\n",
      "0  CC[C@H](C)[C@H](NC(=O)[C@H](CCC(O)=O)NC(=O)[C@...   \n",
      "1  CC(C)C[C@H](NC(=O)[C@@H](COC(C)(C)C)NC(=O)[C@H...   \n",
      "2  CC(C)C[C@@H](NC(=O)CNC(=O)[C@@H](NC=O)C(C)C)C(...   \n",
      "3  NC(=O)CC[C@@H]1NC(=O)[C@H](CC2=CC=CC=C2)NC(=O)...   \n",
      "4  CC(C)C[C@H](NC(=O)[C@@H](CCCNC(N)=O)NC(=O)[C@H...   \n",
      "\n",
      "                                              labels   dataset  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  drugbank   \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  drugbank   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  drugbank   \n",
      "3  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  drugbank   \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  drugbank   \n",
      "\n",
      "                                            adr_text          name  \n",
      "0  Based on a study by Gleason et al., the no-obs...   Bivalirudin  \n",
      "1  No experience of overdosage from clinical trials.     Goserelin  \n",
      "2                                                     Gramicidin D  \n",
      "3  Intravenous TDLo in humans is reported to be 0...  Desmopressin  \n",
      "4                                                       Cetrorelix  \n",
      "(12313, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_drug.head())\n",
    "print(df_drug.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CREATE INPUT TEXT WITH [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:19:10.911977Z",
     "iopub.status.busy": "2025-11-14T14:19:10.911696Z",
     "iopub.status.idle": "2025-11-14T14:19:11.128896Z",
     "shell.execute_reply": "2025-11-14T14:19:11.128304Z",
     "shell.execute_reply.started": "2025-11-14T14:19:10.911959Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_input(row):\n",
    "    smiles = row.get(\"smiles\") if isinstance(row, dict) else row[\"smiles\"]\n",
    "    active = [i for i, v in enumerate(row[\"labels\"]) if float(v) == 1.0]\n",
    "    if not active:\n",
    "        text = \"No activity\"\n",
    "    else:\n",
    "        if row[\"dataset\"] == \"tox21\":\n",
    "            text = \"Tox21 activity: \" + \", \".join([tox_labels[i] for i in active])\n",
    "        elif row[\"dataset\"] == \"sider\":\n",
    "            text = \"Side effects: \" + \", \".join([sider_labels[i] for i in active])\n",
    "        else:\n",
    "            text = \"ADR: \" + \", \".join([common_adrs[i] for i in active])\n",
    "    return str(smiles) + \" [SEP] \" + text\n",
    "\n",
    "# Only create input_text for non-empty dfs\n",
    "if not df_tox.empty:\n",
    "    df_tox[\"input_text\"] = df_tox.apply(create_input, axis=1)\n",
    "if not df_sider.empty:\n",
    "    df_sider[\"input_text\"] = df_sider.apply(create_input, axis=1)\n",
    "if not df_drug.empty:\n",
    "    df_drug[\"input_text\"] = df_drug.apply(create_input, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:19:11.130447Z",
     "iopub.status.busy": "2025-11-14T14:19:11.130227Z",
     "iopub.status.idle": "2025-11-14T14:19:11.143001Z",
     "shell.execute_reply": "2025-11-14T14:19:11.142387Z",
     "shell.execute_reply.started": "2025-11-14T14:19:11.130430Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 21754 samples\n"
     ]
    }
   ],
   "source": [
    "# Gộp (skip any empty)\n",
    "parts = []\n",
    "for d in [df_tox, df_sider, df_drug]:\n",
    "    if not d.empty:\n",
    "        # ensure columns consistent\n",
    "        if 'smiles' not in d.columns and 'SMILES' in d.columns:\n",
    "            d = d.rename(columns={'SMILES':'smiles'})\n",
    "        parts.append(d[['smiles', 'labels', 'dataset', 'input_text']])\n",
    "df_all = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame(columns=['smiles','labels','dataset','input_text'])\n",
    "print(f\"Total: {len(df_all)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:19:11.143985Z",
     "iopub.status.busy": "2025-11-14T14:19:11.143724Z",
     "iopub.status.idle": "2025-11-14T14:19:11.162233Z",
     "shell.execute_reply": "2025-11-14T14:19:11.161446Z",
     "shell.execute_reply.started": "2025-11-14T14:19:11.143960Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles  \\\n",
      "0                       CCOc1ccc2nc(S(N)(=O)=O)sc2c1   \n",
      "1                          CCN1C(=O)NC(c2ccccc2)C1=O   \n",
      "2  CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]...   \n",
      "3                    CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C   \n",
      "4                          CC(O)(P(=O)(O)O)P(=O)(O)O   \n",
      "\n",
      "                                              labels dataset  \\\n",
      "0  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   tox21   \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   tox21   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   tox21   \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   tox21   \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   tox21   \n",
      "\n",
      "                                          input_text  \n",
      "0  CCOc1ccc2nc(S(N)(=O)=O)sc2c1 [SEP] Tox21 activ...  \n",
      "1        CCN1C(=O)NC(c2ccccc2)C1=O [SEP] No activity  \n",
      "2  CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]...  \n",
      "3  CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C [SEP] No activity  \n",
      "4        CC(O)(P(=O)(O)O)P(=O)(O)O [SEP] No activity  \n",
      "Label lengths example: [12, 12, 12, 12, 12]\n"
     ]
    }
   ],
   "source": [
    "print(df_all.head())\n",
    "print(\"Label lengths example:\", [len(x) for x in df_all['labels'].head().tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ToxBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:19:11.163153Z",
     "iopub.status.busy": "2025-11-14T14:19:11.162930Z",
     "iopub.status.idle": "2025-11-14T14:19:11.736573Z",
     "shell.execute_reply": "2025-11-14T14:19:11.735774Z",
     "shell.execute_reply.started": "2025-11-14T14:19:11.163136Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load model: Exscientia/ToxBERT ...\n",
      "Could not load Exscientia/ToxBERT: Exscientia/ToxBERT is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to t\n",
      "Trying to load model: seyonec/ChemBERTa-zinc-base-v1 ...\n",
      "Loaded model: seyonec/ChemBERTa-zinc-base-v1\n"
     ]
    }
   ],
   "source": [
    "PREFERRED = [\"Exscientia/ToxBERT\", \"seyonec/ChemBERTa-zinc-base-v1\", \"bert-base-uncased\"]\n",
    "MODEL_NAME = None\n",
    "tokenizer = None\n",
    "backbone = None\n",
    "\n",
    "for cand in PREFERRED:\n",
    "    try:\n",
    "        print(f\"Trying to load model: {cand} ...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(cand)\n",
    "        backbone = AutoModel.from_pretrained(cand)\n",
    "        MODEL_NAME = cand\n",
    "        print(f\"Loaded model: {cand}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load {cand}: {str(e)[:200]}\")\n",
    "\n",
    "if MODEL_NAME is None:\n",
    "    raise RuntimeError(\"Failed to load any model. Please provide a local pretrained model or set INTERNET access to HuggingFace.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:19:11.738278Z",
     "iopub.status.busy": "2025-11-14T14:19:11.737829Z",
     "iopub.status.idle": "2025-11-14T14:19:12.347583Z",
     "shell.execute_reply": "2025-11-14T14:19:12.346787Z",
     "shell.execute_reply.started": "2025-11-14T14:19:11.738258Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test: 15227/3263/3264\n"
     ]
    }
   ],
   "source": [
    "class MultiTaskDataset:\n",
    "    def __init__(self, df, tokenizer, max_len=256):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            row[\"input_text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(row[\"labels\"], dtype=torch.float),\n",
    "            'dataset': row[\"dataset\"]\n",
    "        }\n",
    "\n",
    "# If df_all is empty -> abort early\n",
    "if df_all.empty:\n",
    "    raise RuntimeError(\"No data in df_all. Check your input CSV/XML files.\")\n",
    "\n",
    "# Split (stratify by dataset)\n",
    "train_df, temp_df = train_test_split(df_all, test_size=0.3, random_state=42, stratify=df_all[\"dataset\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"dataset\"])\n",
    "\n",
    "train_ds = MultiTaskDataset(train_df, tokenizer)\n",
    "val_ds = MultiTaskDataset(val_df, tokenizer)\n",
    "test_ds = MultiTaskDataset(test_df, tokenizer)\n",
    "\n",
    "print(f\"Train/Val/Test: {len(train_ds)}/{len(val_ds)}/{len(test_ds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:19:18.049888Z",
     "iopub.status.busy": "2025-11-14T14:19:18.049553Z",
     "iopub.status.idle": "2025-11-14T14:19:18.089574Z",
     "shell.execute_reply": "2025-11-14T14:19:18.088985Z",
     "shell.execute_reply.started": "2025-11-14T14:19:18.049861Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test: 15227/3263/3264\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "train_df, temp_df = train_test_split(df_all, test_size=0.3, random_state=42, stratify=df_all[\"dataset\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"dataset\"])\n",
    "\n",
    "train_ds = MultiTaskDataset(train_df, tokenizer)\n",
    "val_ds = MultiTaskDataset(val_df, tokenizer)\n",
    "test_ds = MultiTaskDataset(test_df, tokenizer)\n",
    "\n",
    "print(f\"Train/Val/Test: {len(train_ds)}/{len(val_ds)}/{len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Task Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:19:53.266423Z",
     "iopub.status.busy": "2025-11-14T14:19:53.265669Z",
     "iopub.status.idle": "2025-11-14T14:19:53.517344Z",
     "shell.execute_reply": "2025-11-14T14:19:53.516491Z",
     "shell.execute_reply.started": "2025-11-14T14:19:53.266399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ToxBERT_MultiTask(nn.Module):\n",
    "    def __init__(self, backbone, n_tox=12, n_sider=27, n_adr=10):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.head_tox = nn.Linear(self.backbone.config.hidden_size, n_tox)\n",
    "        self.head_sider = nn.Linear(self.backbone.config.hidden_size, n_sider)\n",
    "        self.head_adr = nn.Linear(self.backbone.config.hidden_size, n_adr)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = self.dropout(out.last_hidden_state[:, 0])\n",
    "        return {\n",
    "            'tox21': self.head_tox(pooled),\n",
    "            'sider': self.head_sider(pooled),\n",
    "            'adr': self.head_adr(pooled),\n",
    "            'embedding': pooled\n",
    "        }\n",
    "\n",
    "model = ToxBERT_MultiTask(backbone, n_tox=12, n_sider=len(sider_labels), n_adr=len(common_adrs)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:20:22.283642Z",
     "iopub.status.busy": "2025-11-14T14:20:22.283004Z",
     "iopub.status.idle": "2025-11-14T14:46:44.035610Z",
     "shell.execute_reply": "2025-11-14T14:46:44.034832Z",
     "shell.execute_reply.started": "2025-11-14T14:20:22.283616Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 952/952 [05:10<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 0.5472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 952/952 [05:17<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Loss: 0.3667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 952/952 [05:17<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Loss: 0.2615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 952/952 [05:17<00:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Loss: 0.2411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([b['input_ids'] for b in batch])\n",
    "    attention_mask = torch.stack([b['attention_mask'] for b in batch])\n",
    "    labels = torch.nn.utils.rnn.pad_sequence([b['labels'] for b in batch], batch_first=True, padding_value=0.0)\n",
    "    datasets = [b['dataset'] for b in batch]\n",
    "    return input_ids, attention_mask, labels, datasets\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, collate_fn=collate_fn)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "print(\"\\nTRAINING...\")\n",
    "model.train()\n",
    "NUM_EPOCHS = 5  # thử 5 epoch rồi tăng nếu cần\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for input_ids, attn_mask, labels, datasets in tqdm(train_loader):\n",
    "        input_ids, attn_mask, labels = input_ids.to(device), attn_mask.to(device), labels.to(device)\n",
    "        outputs = model(input_ids, attn_mask)\n",
    "\n",
    "        loss = 0.0\n",
    "        # compute loss per dataset in batch\n",
    "        for ds, head in [('tox21', 'tox21'), ('sider', 'sider'), ('drugbank', 'adr')]:\n",
    "            idx = [i for i, d in enumerate(datasets) if d == ds]\n",
    "            if len(idx) == 0:\n",
    "                continue\n",
    "            batch_labels = labels[idx]\n",
    "            batch_logits = outputs[head][idx]\n",
    "            # slice labels to match head size (B x num_labels)\n",
    "            num_labels = batch_logits.shape[1]\n",
    "            batch_labels = batch_labels[:, :num_labels]\n",
    "            loss += criterion(batch_logits, batch_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation + Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:49:10.607839Z",
     "iopub.status.busy": "2025-11-14T14:49:10.607492Z",
     "iopub.status.idle": "2025-11-14T14:49:54.277406Z",
     "shell.execute_reply": "2025-11-14T14:49:54.276649Z",
     "shell.execute_reply.started": "2025-11-14T14:49:10.607816Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING VAL...\n",
      "TOX21: Micro F1=0.9551, Macro F1=0.9428, Hamming=0.0057\n",
      "SIDER: Micro F1=0.8684, Macro F1=0.7981, Hamming=0.1687\n",
      "DRUGBANK: Micro F1=0.8821, Macro F1=0.6261, Hamming=0.0034\n",
      "\n",
      "EVALUATING TEST...\n",
      "TOX21: Micro F1=0.9641, Macro F1=0.9577, Hamming=0.0046\n",
      "SIDER: Micro F1=0.8695, Macro F1=0.7912, Hamming=0.1525\n",
      "DRUGBANK: Micro F1=0.1056, Macro F1=0.5918, Hamming=0.2035\n"
     ]
    }
   ],
   "source": [
    "def evaluate(loader, name):\n",
    "    model.eval()\n",
    "    all_probs = {'tox21': [], 'sider': [], 'drugbank': []}\n",
    "    all_labels = {'tox21': [], 'sider': [], 'drugbank': []}\n",
    "    all_embs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attn_mask, labels, datasets in loader:\n",
    "            input_ids, attn_mask = input_ids.to(device), attn_mask.to(device)\n",
    "            outputs = model(input_ids, attn_mask)\n",
    "            all_embs.append(outputs['embedding'].cpu().numpy())\n",
    "\n",
    "            for ds in set(datasets):\n",
    "                idx = [i for i, d in enumerate(datasets) if d == ds]\n",
    "                if not idx:\n",
    "                    continue\n",
    "                if ds == 'tox21':\n",
    "                    probs = torch.sigmoid(outputs['tox21'][idx]).cpu().numpy()\n",
    "                    batch_labels = labels[idx, :12].cpu().numpy()\n",
    "                elif ds == 'sider':\n",
    "                    probs = torch.sigmoid(outputs['sider'][idx]).cpu().numpy()\n",
    "                    batch_labels = labels[idx, :len(sider_labels)].cpu().numpy()\n",
    "                else:\n",
    "                    probs = torch.sigmoid(outputs['adr'][idx]).cpu().numpy()\n",
    "                    batch_labels = labels[idx, :len(common_adrs)].cpu().numpy()\n",
    "                all_probs[ds].append(probs)\n",
    "                all_labels[ds].append(batch_labels)\n",
    "\n",
    "    embs = np.vstack(all_embs) if len(all_embs) > 0 else np.zeros((0, model.backbone.config.hidden_size))\n",
    "    results = {}\n",
    "\n",
    "    for ds in all_probs:\n",
    "        if not all_probs[ds]:\n",
    "            continue\n",
    "        probs = np.vstack(all_probs[ds])\n",
    "        labels = np.vstack(all_labels[ds])\n",
    "\n",
    "        # Threshold tuning per class\n",
    "        thresholds = []\n",
    "        for i in range(probs.shape[1]):\n",
    "            try:\n",
    "                p, r, t = precision_recall_curve(labels[:, i], probs[:, i])\n",
    "                f1 = 2 * p * r / (p + r + 1e-8)\n",
    "                best_thr = t[np.argmax(f1)] if len(t) > 0 else 0.5\n",
    "            except Exception:\n",
    "                best_thr = 0.5\n",
    "            thresholds.append(float(best_thr))\n",
    "        thresholds = np.array(thresholds)\n",
    "\n",
    "        preds = (probs > thresholds).astype(int)\n",
    "        micro = f1_score(labels, preds, average='micro') if preds.sum() > 0 else 0.0\n",
    "        macro = f1_score(labels, preds, average='macro') if preds.sum() > 0 else 0.0\n",
    "        hamming = hamming_loss(labels, preds)\n",
    "\n",
    "        results[ds] = {\n",
    "            'micro_f1': micro,\n",
    "            'macro_f1': macro,\n",
    "            'hamming': hamming,\n",
    "            'thresholds': thresholds,\n",
    "            'probs': probs,\n",
    "            'labels': labels,\n",
    "            'preds': preds\n",
    "        }\n",
    "        print(f\"{ds.upper()}: Micro F1={micro:.4f}, Macro F1={macro:.4f}, Hamming={hamming:.4f}\")\n",
    "\n",
    "    return results, embs\n",
    "\n",
    "print(\"\\nEVALUATING VAL...\")\n",
    "val_results, val_embs = evaluate(val_loader, \"val\")\n",
    "\n",
    "print(\"\\nEVALUATING TEST...\")\n",
    "test_results, test_embs = evaluate(test_loader, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:49:54.278827Z",
     "iopub.status.busy": "2025-11-14T14:49:54.278588Z",
     "iopub.status.idle": "2025-11-14T14:51:33.534730Z",
     "shell.execute_reply": "2025-11-14T14:51:33.533915Z",
     "shell.execute_reply.started": "2025-11-14T14:49:54.278809Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED EMBEDDINGS:\n",
      "  embeddings/train_embeddings.pt\n",
      "  embeddings/val_embeddings.pt\n",
      "  embeddings/test_embeddings.pt\n",
      "  embeddings/toxbert_sep_embeddings.pt\n",
      "\n",
      "ALL DONE! ToxBERT + [SEP] for 3 datasets.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"embeddings\", exist_ok=True)\n",
    "\n",
    "# Train embeddings\n",
    "train_embs = []\n",
    "with torch.no_grad():\n",
    "    for input_ids, attn_mask, _, _ in train_loader:\n",
    "        input_ids, attn_mask = input_ids.to(device), attn_mask.to(device)\n",
    "        outputs = model(input_ids, attn_mask)\n",
    "        train_embs.append(outputs['embedding'].cpu().numpy())\n",
    "train_embs = np.vstack(train_embs) if train_embs else np.zeros((0, model.backbone.config.hidden_size))\n",
    "\n",
    "torch.save(train_embs, \"embeddings/train_embeddings.pt\")\n",
    "torch.save(val_embs, \"embeddings/val_embeddings.pt\")\n",
    "torch.save(test_embs, \"embeddings/test_embeddings.pt\")\n",
    "\n",
    "# Save unified .pt like toxbert_sep_embeddings.pt\n",
    "torch.save({\n",
    "    \"train.embeddings\": train_embs,\n",
    "    \"val.embeddings\": val_embs,\n",
    "    \"test.embeddings\": test_embs,\n",
    "    \"val.results\": val_results,\n",
    "    \"test.results\": test_results\n",
    "}, \"embeddings/toxbert_sep_embeddings.pt\")\n",
    "\n",
    "print(\"\\nSAVED EMBEDDINGS:\")\n",
    "print(\"  embeddings/train_embeddings.pt\")\n",
    "print(\"  embeddings/val_embeddings.pt\")\n",
    "print(\"  embeddings/test_embeddings.pt\")\n",
    "print(\"  embeddings/toxbert_sep_embeddings.pt\")\n",
    "\n",
    "print(\"\\nALL DONE! ToxBERT + [SEP] for 3 datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T15:02:09.678972Z",
     "iopub.status.busy": "2025-11-14T15:02:09.678177Z",
     "iopub.status.idle": "2025-11-14T15:02:11.166414Z",
     "shell.execute_reply": "2025-11-14T15:02:11.165798Z",
     "shell.execute_reply.started": "2025-11-14T15:02:09.678946Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (15227, 768)\n",
      "Val shape: (3263, 768)\n",
      "Test shape: (3264, 768)\n",
      "\n",
      "Unified embeddings loaded:\n",
      "Train: (15227, 768)\n",
      "Val: (3263, 768)\n",
      "Test: (3264, 768)\n",
      "Val results: {'tox21': {'micro_f1': 0.9551422319474836, 'macro_f1': 0.9427803789830574, 'hamming': 0.005684969495285635, 'thresholds': array([0.29493877, 0.74007112, 0.90575749, 0.93684632, 0.33415473,\n",
      "       0.33080855, 0.57326126, 0.78087133, 0.19239934, 0.75388807,\n",
      "       0.88252515, 0.19842649]), 'probs': array([[5.4218085e-03, 2.8782657e-01, 4.9252347e-03, ..., 8.6479999e-02,\n",
      "        1.3363129e-02, 8.4319063e-02],\n",
      "       [5.3331151e-04, 4.0536796e-04, 8.0530671e-04, ..., 3.7391108e-04,\n",
      "        8.4800116e-04, 5.6708563e-04],\n",
      "       [1.0848003e-02, 7.0237080e-03, 9.0575749e-01, ..., 1.3857560e-02,\n",
      "        9.8450953e-01, 2.3978163e-02],\n",
      "       ...,\n",
      "       [1.8545841e-01, 4.6415888e-02, 9.7472501e-01, ..., 1.1081588e-02,\n",
      "        1.9614173e-02, 6.6311754e-02],\n",
      "       [9.1101445e-02, 1.2810989e-01, 3.6322575e-03, ..., 5.3570112e-03,\n",
      "        9.9537474e-01, 9.0948604e-03],\n",
      "       [6.6701276e-04, 4.3206933e-04, 6.6813891e-04, ..., 4.0004187e-04,\n",
      "        4.0323279e-04, 4.5546005e-04]], dtype=float32), 'labels': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 1., ..., 0., 1., 0.],\n",
      "       ...,\n",
      "       [0., 0., 1., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 1., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'preds': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 1, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])}, 'sider': {'micro_f1': 0.8683677602268124, 'macro_f1': 0.7981284006664455, 'hamming': 0.1687435098650052, 'thresholds': array([0.48825377, 0.6836673 , 0.01238882, 0.29980308, 0.49757317,\n",
      "       0.30471215, 0.76600528, 0.6759969 , 0.58613694, 0.28028849,\n",
      "       0.09794521, 0.82506943, 0.20042558, 0.18512538, 0.35894564,\n",
      "       0.58705693, 0.63732946, 0.25569418, 0.20500824, 0.26335073,\n",
      "       0.18909715, 0.44723165, 0.15239155, 0.58624953, 0.46059284,\n",
      "       0.63396662, 0.41319016]), 'probs': array([[0.00979862, 0.7545521 , 0.03126328, ..., 0.8182116 , 0.9821317 ,\n",
      "        0.56001383],\n",
      "       [0.07348186, 0.03210128, 0.00981922, ..., 0.06566536, 0.8732072 ,\n",
      "        0.17404431],\n",
      "       [0.98832583, 0.9879902 , 0.01749304, ..., 0.8882292 , 0.98208207,\n",
      "        0.93430156],\n",
      "       ...,\n",
      "       [0.9435464 , 0.6836673 , 0.01091824, ..., 0.6998505 , 0.99074745,\n",
      "        0.6240899 ],\n",
      "       [0.9886079 , 0.92371744, 0.01161576, ..., 0.8404377 , 0.9881159 ,\n",
      "        0.8176005 ],\n",
      "       [0.48825377, 0.95687395, 0.01238882, ..., 0.87456864, 0.99187577,\n",
      "        0.8170163 ]], dtype=float32), 'labels': array([[0., 0., 0., ..., 1., 1., 0.],\n",
      "       [0., 0., 0., ..., 0., 1., 0.],\n",
      "       [1., 1., 0., ..., 0., 1., 0.],\n",
      "       ...,\n",
      "       [1., 1., 0., ..., 1., 1., 1.],\n",
      "       [1., 1., 0., ..., 1., 1., 1.],\n",
      "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32), 'preds': array([[0, 1, 1, ..., 1, 1, 1],\n",
      "       [0, 0, 0, ..., 0, 1, 0],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       ...,\n",
      "       [1, 0, 0, ..., 1, 1, 1],\n",
      "       [1, 1, 0, ..., 1, 1, 1],\n",
      "       [0, 1, 0, ..., 1, 1, 1]])}, 'drugbank': {'micro_f1': 0.8821292775665398, 'macro_f1': 0.6260935524779203, 'hamming': 0.0033567948023822416, 'thresholds': array([0.78649604, 0.70472795, 0.69239706, 0.85327256, 0.18485048,\n",
      "       0.55817866, 0.45328611, 0.0550717 , 0.02462702, 0.02031768]), 'probs': array([[0.00021292, 0.00027693, 0.00019262, ..., 0.00013229, 0.00016606,\n",
      "        0.00013846],\n",
      "       [0.00127007, 0.00190322, 0.00126406, ..., 0.00060632, 0.0010783 ,\n",
      "        0.00046216],\n",
      "       [0.00024488, 0.00031373, 0.00024189, ..., 0.00012597, 0.00015183,\n",
      "        0.00013037],\n",
      "       ...,\n",
      "       [0.00022227, 0.00035021, 0.0001829 , ..., 0.00014023, 0.00018514,\n",
      "        0.0001322 ],\n",
      "       [0.00016993, 0.00030236, 0.00020123, ..., 0.00013206, 0.00015542,\n",
      "        0.00012367],\n",
      "       [0.00027745, 0.0004039 , 0.00030096, ..., 0.00017086, 0.00020147,\n",
      "        0.0001326 ]], dtype=float32), 'labels': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'preds': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])}}\n",
      "Test results: {'tox21': {'micro_f1': 0.9640750670241287, 'macro_f1': 0.9576859566772544, 'hamming': 0.004641174840676087, 'thresholds': array([0.61006427, 0.21265939, 0.49213839, 0.95904726, 0.48801723,\n",
      "       0.29512751, 0.53068483, 0.87055779, 0.38514829, 0.28203282,\n",
      "       0.82788438, 0.23956199]), 'probs': array([[9.6861803e-04, 7.5876655e-04, 5.8415753e-04, ..., 3.9620453e-04,\n",
      "        4.7161788e-04, 6.6250673e-04],\n",
      "       [8.5309643e-04, 5.8604946e-04, 5.6900393e-04, ..., 2.6152522e-04,\n",
      "        1.0139907e-03, 5.1889615e-04],\n",
      "       [4.4760504e-03, 1.2518674e-03, 9.9683064e-01, ..., 8.7392959e-04,\n",
      "        2.0721753e-03, 1.6291429e-03],\n",
      "       ...,\n",
      "       [2.1646288e-03, 8.8822551e-04, 1.3596299e-03, ..., 7.4440875e-04,\n",
      "        6.8395137e-04, 6.9254794e-04],\n",
      "       [2.7268790e-03, 2.3835816e-03, 1.0536485e-03, ..., 1.2281815e-03,\n",
      "        1.0080482e-03, 1.3616217e-03],\n",
      "       [5.7751348e-04, 4.0318663e-04, 7.3941535e-04, ..., 3.3956661e-04,\n",
      "        5.6650600e-04, 5.7421258e-04]], dtype=float32), 'labels': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 1., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'preds': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])}, 'sider': {'micro_f1': 0.8695008146941194, 'macro_f1': 0.791154214277321, 'hamming': 0.15247490481135342, 'thresholds': array([0.83481437, 0.64947033, 0.022378  , 0.2321858 , 0.18542117,\n",
      "       0.4563278 , 0.50220293, 0.48558146, 0.32165462, 0.21212339,\n",
      "       0.18689442, 0.84451526, 0.2593348 , 0.29544646, 0.4586128 ,\n",
      "       0.35919333, 0.66187918, 0.23170249, 0.40427169, 0.46212858,\n",
      "       0.44372967, 0.2728467 , 0.18297449, 0.3625994 , 0.27931961,\n",
      "       0.53553253, 0.53311908]), 'probs': array([[0.12080321, 0.9715208 , 0.01284121, ..., 0.6571075 , 0.9625427 ,\n",
      "        0.70778835],\n",
      "       [0.98387754, 0.96161574, 0.02092131, ..., 0.94549453, 0.9854855 ,\n",
      "        0.9742348 ],\n",
      "       [0.99188155, 0.9364498 , 0.01786009, ..., 0.8870606 , 0.99042493,\n",
      "        0.8540501 ],\n",
      "       ...,\n",
      "       [0.0511594 , 0.08360378, 0.00797141, ..., 0.1593008 , 0.83389455,\n",
      "        0.18814853],\n",
      "       [0.99398637, 0.9770553 , 0.01823301, ..., 0.88587415, 0.98893166,\n",
      "        0.8101535 ],\n",
      "       [0.01520191, 0.47718686, 0.01638539, ..., 0.8283135 , 0.9773417 ,\n",
      "        0.6093576 ]], dtype=float32), 'labels': array([[0., 1., 0., ..., 1., 1., 1.],\n",
      "       [1., 1., 0., ..., 0., 1., 1.],\n",
      "       [1., 0., 0., ..., 1., 1., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 1., 0.],\n",
      "       [1., 1., 0., ..., 0., 1., 1.],\n",
      "       [0., 1., 0., ..., 1., 1., 1.]], dtype=float32), 'preds': array([[0, 1, 0, ..., 1, 1, 1],\n",
      "       [1, 1, 0, ..., 1, 1, 1],\n",
      "       [1, 1, 0, ..., 1, 1, 1],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 1, 0],\n",
      "       [1, 1, 0, ..., 1, 1, 1],\n",
      "       [0, 0, 0, ..., 1, 1, 1]])}, 'drugbank': {'micro_f1': 0.10563882940756601, 'macro_f1': 0.5917775817045132, 'hamming': 0.20351922035733622, 'thresholds': array([7.28547752e-01, 3.89695168e-01, 7.19448328e-01, 8.11926365e-01,\n",
      "       2.54304618e-01, 4.43967968e-01, 1.60598829e-01, 8.13057559e-05,\n",
      "       2.00244766e-02, 8.30462814e-05]), 'probs': array([[0.00021517, 0.00030408, 0.00021957, ..., 0.00013559, 0.00017095,\n",
      "        0.00010831],\n",
      "       [0.00056818, 0.00073645, 0.00057182, ..., 0.00028209, 0.00042212,\n",
      "        0.0002112 ],\n",
      "       [0.00022661, 0.0003173 , 0.00025305, ..., 0.00012885, 0.00020366,\n",
      "        0.0001364 ],\n",
      "       ...,\n",
      "       [0.00017696, 0.00026613, 0.00016857, ..., 0.00012915, 0.00017752,\n",
      "        0.00013082],\n",
      "       [0.00034865, 0.00056799, 0.00037362, ..., 0.00020186, 0.00027652,\n",
      "        0.00018069],\n",
      "       [0.00087944, 0.00071337, 0.00032838, ..., 0.00027628, 0.00023195,\n",
      "        0.0001515 ]], dtype=float32), 'labels': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'preds': array([[0, 0, 0, ..., 1, 0, 1],\n",
      "       [0, 0, 0, ..., 1, 0, 1],\n",
      "       [0, 0, 0, ..., 1, 0, 1],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 1, 0, 1],\n",
      "       [0, 0, 0, ..., 1, 0, 1],\n",
      "       [0, 0, 0, ..., 1, 0, 1]])}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load từng embeddings\n",
    "train_embs = torch.load(\"/kaggle/working/embeddings/train_embeddings.pt\", weights_only=False)\n",
    "val_embs   = torch.load(\"/kaggle/working/embeddings/val_embeddings.pt\", weights_only=False)\n",
    "test_embs  = torch.load(\"/kaggle/working/embeddings/test_embeddings.pt\", weights_only=False)\n",
    "\n",
    "print(\"Train shape:\", train_embs.shape)\n",
    "print(\"Val shape:\", val_embs.shape)\n",
    "print(\"Test shape:\", test_embs.shape)\n",
    "\n",
    "# Load unified embeddings\n",
    "toxbert_data = torch.load(\"/kaggle/working/embeddings/toxbert_sep_embeddings.pt\", weights_only=False)\n",
    "\n",
    "train_embs2 = toxbert_data[\"train.embeddings\"]\n",
    "val_embs2   = toxbert_data[\"val.embeddings\"]\n",
    "test_embs2  = toxbert_data[\"test.embeddings\"]\n",
    "val_results = toxbert_data[\"val.results\"]\n",
    "test_results = toxbert_data[\"test.results\"]\n",
    "\n",
    "print(\"\\nUnified embeddings loaded:\")\n",
    "print(\"Train:\", train_embs2.shape)\n",
    "print(\"Val:\", val_embs2.shape)\n",
    "print(\"Test:\", test_embs2.shape)\n",
    "print(\"Val results:\", val_results)\n",
    "print(\"Test results:\", test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T15:02:24.558524Z",
     "iopub.status.busy": "2025-11-14T15:02:24.557825Z",
     "iopub.status.idle": "2025-11-14T15:02:24.574264Z",
     "shell.execute_reply": "2025-11-14T15:02:24.573586Z",
     "shell.execute_reply.started": "2025-11-14T15:02:24.558503Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train.embeddings': array([[ 0.24542175,  0.4627934 ,  0.42310736, ..., -0.5836917 ,\n",
       "         -0.6105582 , -0.5732417 ],\n",
       "        [ 0.38368216, -1.0461295 , -1.4433533 , ...,  0.73406404,\n",
       "          1.7207364 , -1.0521164 ],\n",
       "        [-0.15846848,  0.768257  ,  0.3528445 , ..., -0.8126923 ,\n",
       "         -0.78711903, -0.479071  ],\n",
       "        ...,\n",
       "        [ 0.20116866,  1.9362442 ,  0.834899  , ..., -0.7820928 ,\n",
       "         -0.4003265 ,  0.03537117],\n",
       "        [-0.31408077,  0.70126486,  0.47756952, ..., -0.8560412 ,\n",
       "         -0.8567976 , -0.4752864 ],\n",
       "        [-0.38004762, -0.53846455,  0.26190087, ..., -2.0576403 ,\n",
       "          0.02896108, -0.25180188]], dtype=float32),\n",
       " 'val.embeddings': array([[-0.41426033,  0.7869829 ,  0.43471563, ..., -0.82132787,\n",
       "         -0.9143279 , -0.4941279 ],\n",
       "        [ 1.006086  , -1.3784261 ,  0.1215761 , ...,  0.45979875,\n",
       "         -1.4841064 , -0.27623513],\n",
       "        [ 1.4632021 ,  0.94343305,  0.75765914, ..., -0.2837115 ,\n",
       "          0.39640746, -0.38931254],\n",
       "        ...,\n",
       "        [-0.39847356,  0.94465405,  0.2913876 , ..., -0.94312805,\n",
       "         -0.82506377, -0.67344224],\n",
       "        [ 1.2971818 ,  1.0257747 ,  0.64816195, ..., -0.01430432,\n",
       "          0.6993662 , -0.59834194],\n",
       "        [ 0.394333  ,  0.79726213,  0.41416675, ..., -0.6030482 ,\n",
       "         -0.37441215, -0.5430579 ]], dtype=float32),\n",
       " 'test.embeddings': array([[ 1.1017338 ,  1.0607022 ,  0.6386037 , ..., -0.2626941 ,\n",
       "          0.38990882, -0.48738408],\n",
       "        [ 0.3465331 ,  1.08401   ,  0.40145078, ..., -0.6545357 ,\n",
       "         -0.6147868 , -0.5725339 ],\n",
       "        [ 0.89981353,  0.87612945,  0.60355145, ..., -0.17304778,\n",
       "          0.3813609 , -0.47918165],\n",
       "        ...,\n",
       "        [-0.04375165,  0.7951009 ,  0.12041838, ..., -0.33547008,\n",
       "         -1.0553993 , -0.4768246 ],\n",
       "        [ 0.57064116,  0.68593407,  0.45731768, ...,  0.07266675,\n",
       "         -0.8400688 , -0.8767256 ],\n",
       "        [ 1.7087885 ,  0.8296016 ,  0.75931585, ...,  0.1501708 ,\n",
       "          1.0066915 , -0.11993717]], dtype=float32),\n",
       " 'val.results': {'tox21': {'micro_f1': 0.9551422319474836,\n",
       "   'macro_f1': 0.9427803789830574,\n",
       "   'hamming': 0.005684969495285635,\n",
       "   'thresholds': array([0.29493877, 0.74007112, 0.90575749, 0.93684632, 0.33415473,\n",
       "          0.33080855, 0.57326126, 0.78087133, 0.19239934, 0.75388807,\n",
       "          0.88252515, 0.19842649]),\n",
       "   'probs': array([[5.4218085e-03, 2.8782657e-01, 4.9252347e-03, ..., 8.6479999e-02,\n",
       "           1.3363129e-02, 8.4319063e-02],\n",
       "          [5.3331151e-04, 4.0536796e-04, 8.0530671e-04, ..., 3.7391108e-04,\n",
       "           8.4800116e-04, 5.6708563e-04],\n",
       "          [1.0848003e-02, 7.0237080e-03, 9.0575749e-01, ..., 1.3857560e-02,\n",
       "           9.8450953e-01, 2.3978163e-02],\n",
       "          ...,\n",
       "          [1.8545841e-01, 4.6415888e-02, 9.7472501e-01, ..., 1.1081588e-02,\n",
       "           1.9614173e-02, 6.6311754e-02],\n",
       "          [9.1101445e-02, 1.2810989e-01, 3.6322575e-03, ..., 5.3570112e-03,\n",
       "           9.9537474e-01, 9.0948604e-03],\n",
       "          [6.6701276e-04, 4.3206933e-04, 6.6813891e-04, ..., 4.0004187e-04,\n",
       "           4.0323279e-04, 4.5546005e-04]], dtype=float32),\n",
       "   'labels': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 1., ..., 0., 1., 0.],\n",
       "          ...,\n",
       "          [0., 0., 1., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 1., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       "   'preds': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 1, 0],\n",
       "          ...,\n",
       "          [0, 0, 1, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 1, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]])},\n",
       "  'sider': {'micro_f1': 0.8683677602268124,\n",
       "   'macro_f1': 0.7981284006664455,\n",
       "   'hamming': 0.1687435098650052,\n",
       "   'thresholds': array([0.48825377, 0.6836673 , 0.01238882, 0.29980308, 0.49757317,\n",
       "          0.30471215, 0.76600528, 0.6759969 , 0.58613694, 0.28028849,\n",
       "          0.09794521, 0.82506943, 0.20042558, 0.18512538, 0.35894564,\n",
       "          0.58705693, 0.63732946, 0.25569418, 0.20500824, 0.26335073,\n",
       "          0.18909715, 0.44723165, 0.15239155, 0.58624953, 0.46059284,\n",
       "          0.63396662, 0.41319016]),\n",
       "   'probs': array([[0.00979862, 0.7545521 , 0.03126328, ..., 0.8182116 , 0.9821317 ,\n",
       "           0.56001383],\n",
       "          [0.07348186, 0.03210128, 0.00981922, ..., 0.06566536, 0.8732072 ,\n",
       "           0.17404431],\n",
       "          [0.98832583, 0.9879902 , 0.01749304, ..., 0.8882292 , 0.98208207,\n",
       "           0.93430156],\n",
       "          ...,\n",
       "          [0.9435464 , 0.6836673 , 0.01091824, ..., 0.6998505 , 0.99074745,\n",
       "           0.6240899 ],\n",
       "          [0.9886079 , 0.92371744, 0.01161576, ..., 0.8404377 , 0.9881159 ,\n",
       "           0.8176005 ],\n",
       "          [0.48825377, 0.95687395, 0.01238882, ..., 0.87456864, 0.99187577,\n",
       "           0.8170163 ]], dtype=float32),\n",
       "   'labels': array([[0., 0., 0., ..., 1., 1., 0.],\n",
       "          [0., 0., 0., ..., 0., 1., 0.],\n",
       "          [1., 1., 0., ..., 0., 1., 0.],\n",
       "          ...,\n",
       "          [1., 1., 0., ..., 1., 1., 1.],\n",
       "          [1., 1., 0., ..., 1., 1., 1.],\n",
       "          [1., 1., 1., ..., 1., 1., 1.]], dtype=float32),\n",
       "   'preds': array([[0, 1, 1, ..., 1, 1, 1],\n",
       "          [0, 0, 0, ..., 0, 1, 0],\n",
       "          [1, 1, 1, ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 0, 0, ..., 1, 1, 1],\n",
       "          [1, 1, 0, ..., 1, 1, 1],\n",
       "          [0, 1, 0, ..., 1, 1, 1]])},\n",
       "  'drugbank': {'micro_f1': 0.8821292775665398,\n",
       "   'macro_f1': 0.6260935524779203,\n",
       "   'hamming': 0.0033567948023822416,\n",
       "   'thresholds': array([0.78649604, 0.70472795, 0.69239706, 0.85327256, 0.18485048,\n",
       "          0.55817866, 0.45328611, 0.0550717 , 0.02462702, 0.02031768]),\n",
       "   'probs': array([[0.00021292, 0.00027693, 0.00019262, ..., 0.00013229, 0.00016606,\n",
       "           0.00013846],\n",
       "          [0.00127007, 0.00190322, 0.00126406, ..., 0.00060632, 0.0010783 ,\n",
       "           0.00046216],\n",
       "          [0.00024488, 0.00031373, 0.00024189, ..., 0.00012597, 0.00015183,\n",
       "           0.00013037],\n",
       "          ...,\n",
       "          [0.00022227, 0.00035021, 0.0001829 , ..., 0.00014023, 0.00018514,\n",
       "           0.0001322 ],\n",
       "          [0.00016993, 0.00030236, 0.00020123, ..., 0.00013206, 0.00015542,\n",
       "           0.00012367],\n",
       "          [0.00027745, 0.0004039 , 0.00030096, ..., 0.00017086, 0.00020147,\n",
       "           0.0001326 ]], dtype=float32),\n",
       "   'labels': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       "   'preds': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]])}},\n",
       " 'test.results': {'tox21': {'micro_f1': 0.9640750670241287,\n",
       "   'macro_f1': 0.9576859566772544,\n",
       "   'hamming': 0.004641174840676087,\n",
       "   'thresholds': array([0.61006427, 0.21265939, 0.49213839, 0.95904726, 0.48801723,\n",
       "          0.29512751, 0.53068483, 0.87055779, 0.38514829, 0.28203282,\n",
       "          0.82788438, 0.23956199]),\n",
       "   'probs': array([[9.6861803e-04, 7.5876655e-04, 5.8415753e-04, ..., 3.9620453e-04,\n",
       "           4.7161788e-04, 6.6250673e-04],\n",
       "          [8.5309643e-04, 5.8604946e-04, 5.6900393e-04, ..., 2.6152522e-04,\n",
       "           1.0139907e-03, 5.1889615e-04],\n",
       "          [4.4760504e-03, 1.2518674e-03, 9.9683064e-01, ..., 8.7392959e-04,\n",
       "           2.0721753e-03, 1.6291429e-03],\n",
       "          ...,\n",
       "          [2.1646288e-03, 8.8822551e-04, 1.3596299e-03, ..., 7.4440875e-04,\n",
       "           6.8395137e-04, 6.9254794e-04],\n",
       "          [2.7268790e-03, 2.3835816e-03, 1.0536485e-03, ..., 1.2281815e-03,\n",
       "           1.0080482e-03, 1.3616217e-03],\n",
       "          [5.7751348e-04, 4.0318663e-04, 7.3941535e-04, ..., 3.3956661e-04,\n",
       "           5.6650600e-04, 5.7421258e-04]], dtype=float32),\n",
       "   'labels': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 1., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       "   'preds': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 1, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]])},\n",
       "  'sider': {'micro_f1': 0.8695008146941194,\n",
       "   'macro_f1': 0.791154214277321,\n",
       "   'hamming': 0.15247490481135342,\n",
       "   'thresholds': array([0.83481437, 0.64947033, 0.022378  , 0.2321858 , 0.18542117,\n",
       "          0.4563278 , 0.50220293, 0.48558146, 0.32165462, 0.21212339,\n",
       "          0.18689442, 0.84451526, 0.2593348 , 0.29544646, 0.4586128 ,\n",
       "          0.35919333, 0.66187918, 0.23170249, 0.40427169, 0.46212858,\n",
       "          0.44372967, 0.2728467 , 0.18297449, 0.3625994 , 0.27931961,\n",
       "          0.53553253, 0.53311908]),\n",
       "   'probs': array([[0.12080321, 0.9715208 , 0.01284121, ..., 0.6571075 , 0.9625427 ,\n",
       "           0.70778835],\n",
       "          [0.98387754, 0.96161574, 0.02092131, ..., 0.94549453, 0.9854855 ,\n",
       "           0.9742348 ],\n",
       "          [0.99188155, 0.9364498 , 0.01786009, ..., 0.8870606 , 0.99042493,\n",
       "           0.8540501 ],\n",
       "          ...,\n",
       "          [0.0511594 , 0.08360378, 0.00797141, ..., 0.1593008 , 0.83389455,\n",
       "           0.18814853],\n",
       "          [0.99398637, 0.9770553 , 0.01823301, ..., 0.88587415, 0.98893166,\n",
       "           0.8101535 ],\n",
       "          [0.01520191, 0.47718686, 0.01638539, ..., 0.8283135 , 0.9773417 ,\n",
       "           0.6093576 ]], dtype=float32),\n",
       "   'labels': array([[0., 1., 0., ..., 1., 1., 1.],\n",
       "          [1., 1., 0., ..., 0., 1., 1.],\n",
       "          [1., 0., 0., ..., 1., 1., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 1., 0.],\n",
       "          [1., 1., 0., ..., 0., 1., 1.],\n",
       "          [0., 1., 0., ..., 1., 1., 1.]], dtype=float32),\n",
       "   'preds': array([[0, 1, 0, ..., 1, 1, 1],\n",
       "          [1, 1, 0, ..., 1, 1, 1],\n",
       "          [1, 1, 0, ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 1, 0],\n",
       "          [1, 1, 0, ..., 1, 1, 1],\n",
       "          [0, 0, 0, ..., 1, 1, 1]])},\n",
       "  'drugbank': {'micro_f1': 0.10563882940756601,\n",
       "   'macro_f1': 0.5917775817045132,\n",
       "   'hamming': 0.20351922035733622,\n",
       "   'thresholds': array([7.28547752e-01, 3.89695168e-01, 7.19448328e-01, 8.11926365e-01,\n",
       "          2.54304618e-01, 4.43967968e-01, 1.60598829e-01, 8.13057559e-05,\n",
       "          2.00244766e-02, 8.30462814e-05]),\n",
       "   'probs': array([[0.00021517, 0.00030408, 0.00021957, ..., 0.00013559, 0.00017095,\n",
       "           0.00010831],\n",
       "          [0.00056818, 0.00073645, 0.00057182, ..., 0.00028209, 0.00042212,\n",
       "           0.0002112 ],\n",
       "          [0.00022661, 0.0003173 , 0.00025305, ..., 0.00012885, 0.00020366,\n",
       "           0.0001364 ],\n",
       "          ...,\n",
       "          [0.00017696, 0.00026613, 0.00016857, ..., 0.00012915, 0.00017752,\n",
       "           0.00013082],\n",
       "          [0.00034865, 0.00056799, 0.00037362, ..., 0.00020186, 0.00027652,\n",
       "           0.00018069],\n",
       "          [0.00087944, 0.00071337, 0.00032838, ..., 0.00027628, 0.00023195,\n",
       "           0.0001515 ]], dtype=float32),\n",
       "   'labels': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       "   'preds': array([[0, 0, 0, ..., 1, 0, 1],\n",
       "          [0, 0, 0, ..., 1, 0, 1],\n",
       "          [0, 0, 0, ..., 1, 0, 1],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 1, 0, 1],\n",
       "          [0, 0, 0, ..., 1, 0, 1],\n",
       "          [0, 0, 0, ..., 1, 0, 1]])}}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxbert_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "def test_bert_embeddings(\n",
    "    bert_model_path,\n",
    "    embedding_file,\n",
    "    smiles_file,\n",
    "    num_samples=20,\n",
    "    tolerance=1e-5\n",
    "):\n",
    "    print(\"=== LOADING MODEL & TOKENIZER ===\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(bert_model_path)\n",
    "    model = AutoModel.from_pretrained(bert_model_path)\n",
    "    model.eval()\n",
    "\n",
    "    print(\"=== LOADING EMBEDDING FILE ===\")\n",
    "    emb = np.load(embedding_file)\n",
    "    print(\"Embedding shape:\", emb.shape)\n",
    "\n",
    "    print(\"=== LOADING SMILES FILE ===\")\n",
    "    with open(smiles_file, \"r\") as f:\n",
    "        smiles_list = [line.strip() for line in f]\n",
    "\n",
    "    if len(smiles_list) != emb.shape[0]:\n",
    "        print(f\"⚠️ WARNING: SMILES count = {len(smiles_list)}, embedding count = {emb.shape[0]} → Không khớp!\")\n",
    "    else:\n",
    "        print(f\"OK: {len(smiles_list)} SMILES khớp với embedding count\")\n",
    "\n",
    "    print(\"\\n=== TESTING FIRST SAMPLES ===\")\n",
    "\n",
    "    for i, smi in enumerate(smiles_list[:num_samples]):\n",
    "        tokens = tokenizer(\n",
    "            smi,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokens)\n",
    "\n",
    "            # Lấy embedding CLS token (chuẩn nhất)\n",
    "            cls_emb = outputs.last_hidden_state[:, 0, :].squeeze(0).numpy()\n",
    "\n",
    "        # Tính độ lệch\n",
    "        diff = np.abs(cls_emb - emb[i]).mean()\n",
    "\n",
    "        print(f\"Sample {i} | SMILES: {smi[:50]}... | mean abs diff = {diff}\")\n",
    "\n",
    "        if diff > tolerance:\n",
    "            print(\"❌ FAIL: embedding không khớp – file này KHÔNG PHẢI embedding từ mô hình này hoặc không phải từ SMILES này!\")\n",
    "            return False\n",
    "\n",
    "    print(\"\\n✅ SUCCESS: Toàn bộ embedding trùng khớp → file embedding là từ đúng mô hình + đúng dữ liệu.\")\n",
    "    return True\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ==== CHẠY TEST TẠI ĐÂY =====\n",
    "# ============================\n",
    "\n",
    "bert_model_path = \"../ToxBERT/checkpoint\"           # path model BERT của bạn\n",
    "embedding_file = \"../ToxBERT/embedding/train_embeddings.npy\"\n",
    "smiles_file = \"../Tox21/smiles_train.txt\"          # file SMILES tương ứng với embeddings\n",
    "\n",
    "test_bert_embeddings(\n",
    "    bert_model_path=bert_model_path,\n",
    "    embedding_file=embedding_file,\n",
    "    smiles_file=smiles_file,\n",
    "    num_samples=20,      # test 20 mẫu đầu tiên\n",
    "    tolerance=1e-5       # độ sai lệch cho phép\n",
    ")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8708602,
     "sourceId": 13691955,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
