{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de80b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49201d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constant\n",
    "TEST_EMBEDDING_FILE = \"test_embeddings.pt\"\n",
    "TRAIN_EMBEDDING_FILE = \"train_embeddings.pt\"\n",
    "VAL_EMBEDDING_FILE = \"val_embeddings.pt\"\n",
    "\n",
    "GNN_TEST_EMBEDDING = f\"../GATNN/embeddings/{TEST_EMBEDDING_FILE}\"\n",
    "GNN_TRAIN_EMBEDDING = f\"../GATNN/embeddings/{TRAIN_EMBEDDING_FILE}\"\n",
    "GNN_VAL_EMBEDDING = f\"../GATNN/embeddings/{VAL_EMBEDDING_FILE}\"\n",
    "BERT_TEST_EMBEDDING = f\"../BERT/embedding/{TEST_EMBEDDING_FILE}\"\n",
    "BERT_TRAIN_EMBEDDING = f\"../BERT/embedding/{TRAIN_EMBEDDING_FILE}\"\n",
    "BERT_VAL_EMBEDDING = f\"../BERT/embedding/{VAL_EMBEDDING_FILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b29f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNN_FILE = \"gat_embeddings.pt\"\n",
    "BERT_FILE = \"all_embeddings.pt\"\n",
    "GNN_EMBEDDING = f\"../GATNN/embeddings/{GNN_FILE}\"\n",
    "BERT_EMBEDDING = f\"../BERT/embedding/{BERT_FILE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df0c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_file(path):\n",
    "    \"\"\"\n",
    "    Hàm load file embedding từ đường dẫn `path`.\n",
    "    Tự động nhận dạng nhiều kiểu dữ liệu khác nhau:\n",
    "    - dict có key 'embeddings' hoặc 'emb', 'vectors', 'features'\n",
    "    - trực tiếp là Tensor\n",
    "    - list/tuple (chuyển sang Tensor)\n",
    "    \"\"\"\n",
    "    # ---- Bỏ chặn numpy pickle cổ ----\n",
    "    try:\n",
    "        torch.serialization.add_safe_globals([np.core.multiarray._reconstruct])\n",
    "    except Exception:\n",
    "        pass  # không sao\n",
    "\n",
    "    # Load thử với weights_only=False ----\n",
    "    try:\n",
    "        data = torch.load(path, weights_only=False)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"LỖI load file embedding: {e}\")\n",
    "    \n",
    "    # data = torch.load(path, map_location='cpu')\n",
    "\n",
    "    #Chuẩn hóa về tensor ----\n",
    "    # Nếu là tensor trực tiếp\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        return {'embeddings': data}\n",
    "    \n",
    "\n",
    "    # Nếu là numpy\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return {'embeddings': torch.tensor(data)}\n",
    "    \n",
    "\n",
    "    # Trường hợp 1: File lưu dạng dict\n",
    "    if isinstance(data, dict):\n",
    "\n",
    "        # TH1.1: Dict có key phổ biến 'embeddings'\n",
    "        if 'embeddings' in data:\n",
    "            return {\n",
    "                'embeddings': torch.as_tensor(data['embeddings']),\n",
    "                'ids': data.get('mol_ids', None)  or data.get('mol_id',None) # có thể không có\n",
    "            }\n",
    "\n",
    "        # TH1.2: Một số file embedding dùng key khác\n",
    "        for key in ['emb', 'vectors', 'features']:\n",
    "            if key in data:\n",
    "                return {\n",
    "                    'embeddings': torch.as_tensor(data[key]),\n",
    "                    'ids': data.get('mol_ids', None) or data.get('mol_id',None)\n",
    "                }\n",
    "\n",
    "        # TH1.3: Dict không rõ cấu trúc → thử convert cả dict sang tensor\n",
    "        try:\n",
    "            return {'embeddings': torch.as_tensor(data)}\n",
    "        except Exception:\n",
    "            raise ValueError(\n",
    "                f\"Lỗi: Dict trong file {path} có cấu trúc không hỗ trợ để chuyển sang Tensor\"\n",
    "            )\n",
    "\n",
    "    \n",
    "\n",
    "    # Trường hợp 3: File là list hoặc tuple → convert sang Tensor\n",
    "    elif isinstance(data, (list, tuple)):\n",
    "        try:\n",
    "            return {'embeddings': torch.as_tensor(data)}\n",
    "        except Exception:\n",
    "            raise ValueError(\n",
    "                f\"Lỗi: Không thể chuyển list/tuple trong file {path} sang Tensor\"\n",
    "            )\n",
    "\n",
    "    # Trường hợp không thuộc loại nào\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Lỗi: Định dạng dữ liệu trong file {path} không được hỗ trợ\"\n",
    "            f\"Loại: {type(data)}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73042a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KIỂM TRA BERT BRANCH==================================\n",
      "KIỂM TRA FILE: ../BERT/embedding/test_embeddings.pt ======\n",
      "✅File hợp lệ!\n",
      "Kích thước: (802, 768)___Kiểu dữ liệu: torch.float32___Có IDs không? Có\n",
      "KIỂM TRA FILE: ../BERT/embedding/train_embeddings.pt ======\n",
      "✅File hợp lệ!\n",
      "Kích thước: (6411, 768)___Kiểu dữ liệu: torch.float32___Có IDs không? Có\n",
      "KIỂM TRA FILE: ../BERT/embedding/val_embeddings.pt ======\n",
      "✅File hợp lệ!\n",
      "Kích thước: (801, 768)___Kiểu dữ liệu: torch.float32___Có IDs không? Có\n",
      "KIỂM TRA FILE: ../BERT/embedding/all_embeddings.pt ======\n",
      "✅File hợp lệ!\n",
      "Kích thước: (8014, 768)___Kiểu dữ liệu: torch.float32___Có IDs không? Có\n",
      "KIỂM TRA GNN BRANCH====================================\n",
      "KIỂM TRA FILE: ../GATNN/embeddings/test_embeddings.pt ======\n",
      "✅File hợp lệ!\n",
      "Kích thước: (801, 512)___Kiểu dữ liệu: torch.float32___Có IDs không? Có\n",
      "KIỂM TRA FILE: ../GATNN/embeddings/train_embeddings.pt ======\n",
      "✅File hợp lệ!\n",
      "Kích thước: (6404, 512)___Kiểu dữ liệu: torch.float32___Có IDs không? Có\n",
      "KIỂM TRA FILE: ../GATNN/embeddings/val_embeddings.pt ======\n",
      "✅File hợp lệ!\n",
      "Kích thước: (801, 512)___Kiểu dữ liệu: torch.float32___Có IDs không? Có\n",
      "KIỂM TRA FILE: ../GATNN/embeddings/gat_embeddings.pt ======\n",
      "✅File hợp lệ!\n",
      "Kích thước: (8006, 512)___Kiểu dữ liệu: torch.float32___Có IDs không? Có\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "def check_embedding_file(path):\n",
    "    \"\"\"Kiểm tra 1 file embedding và trả về True/False + in thông tin chi tiết.\"\"\"\n",
    "\n",
    "    print(f\"KIỂM TRA FILE: {path} ======\")\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        print(\"Lỗi: File không tồn tại.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        result = load_embedding_file(path)\n",
    "        emb = result[\"embeddings\"]\n",
    "\n",
    "        # --- Kiểm tra embedding có phải Tensor ---\n",
    "        if not isinstance(emb, torch.Tensor):\n",
    "            print(\"Lỗi: embeddings không phải Torch.Tensor.\")\n",
    "            return False\n",
    "\n",
    "        # --- Kiểm tra số chiều ---\n",
    "        if emb.ndim < 2:\n",
    "            print(f\"Lỗi: embeddings phải >= 2 chiều, hiện tại: {emb.ndim}\")\n",
    "            return False\n",
    "\n",
    "        # --- In thông tin hợp lệ ---\n",
    "        print(\"✅File hợp lệ!\")\n",
    "        print(f\"Kích thước: {tuple(emb.shape)}___Kiểu dữ liệu: {emb.dtype}___Có IDs không? { 'Có' if result.get('ids') is not None else 'Không' }\")\n",
    "       \n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi load file: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_all_embeddings():\n",
    "    \"\"\"Test toàn bộ file BERT + GNN\"\"\"\n",
    "\n",
    "    bert_files = [\n",
    "        BERT_TEST_EMBEDDING,\n",
    "        BERT_TRAIN_EMBEDDING,\n",
    "        BERT_VAL_EMBEDDING,\n",
    "        BERT_EMBEDDING\n",
    "    ]\n",
    "\n",
    "    gnn_files = [\n",
    "        GNN_TEST_EMBEDDING,\n",
    "        GNN_TRAIN_EMBEDDING,\n",
    "        GNN_VAL_EMBEDDING,\n",
    "        GNN_EMBEDDING\n",
    "    ]\n",
    "\n",
    "   \n",
    "    print(\"KIỂM TRA BERT BRANCH==================================\")\n",
    "  \n",
    "\n",
    "    for f in bert_files:\n",
    "        check_embedding_file(f)\n",
    "\n",
    "    \n",
    "    print(\"KIỂM TRA GNN BRANCH====================================\")\n",
    "\n",
    "    for f in gnn_files:\n",
    "        check_embedding_file(f)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_all_embeddings()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c187148",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_all = torch.load(BERT_EMBEDDING, weights_only=False)\n",
    "gat_all = torch.load(GNN_EMBEDDING, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5d64f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_all:\n",
      "<class 'dict'>\n",
      "dict_keys(['embeddings', 'mol_id', 'labels'])\n",
      "gat_all:\n",
      "<class 'dict'>\n",
      "dict_keys(['embeddings', 'logits', 'probabilities', 'labels', 'mol_ids', 'num_graphs', 'embedding_dim', 'num_classes'])\n"
     ]
    }
   ],
   "source": [
    "print('bert_all:')\n",
    "print(type(bert_all))\n",
    "print(bert_all.keys())\n",
    "print('gat_all:')\n",
    "print(type(gat_all))\n",
    "print(gat_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1dd2c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng mẫu BERT: 8014\n",
      "Số lượng mẫu GAT: 8006\n",
      "\n",
      "5 ID đầu tiên của BERT: ['TOX31644', 'TOX7580', 'TOX24399', 'TOX5307', 'TOX26872']\n",
      "5 ID đầu tiên của GAT: ['TOX13161', 'TOX29296', 'TOX4629', 'TOX213', 'TOX25950']\n",
      "Tổng số ID trong BERT: 8014\n",
      "Tổng số ID trong GAT: 8006\n",
      "Số ID giao nhau: 8006\n",
      "Số ID BERT có nhưng GAT không có: 8\n",
      "Số ID GAT có nhưng BERT không có: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Số lượng mẫu BERT:\", len(bert_all['mol_id']))\n",
    "print(\"Số lượng mẫu GAT:\", len(gat_all['mol_ids']))\n",
    "\n",
    "print(\"\\n5 ID đầu tiên của BERT:\", bert_all['mol_id'][:5])\n",
    "print(\"5 ID đầu tiên của GAT:\", gat_all['mol_ids'][:5])\n",
    "\n",
    "\n",
    "bert_ids = set(bert_all['mol_id'])\n",
    "gat_ids = set(gat_all['mol_ids'])\n",
    "\n",
    "intersection_ids = bert_ids.intersection(gat_ids)\n",
    "missing_in_gat = bert_ids - gat_ids\n",
    "missing_in_bert = gat_ids - bert_ids\n",
    "\n",
    "print(\"Tổng số ID trong BERT:\", len(bert_ids))\n",
    "print(\"Tổng số ID trong GAT:\", len(gat_ids))\n",
    "print(\"Số ID giao nhau:\", len(intersection_ids))\n",
    "print(\"Số ID BERT có nhưng GAT không có:\", len(missing_in_gat))\n",
    "print(\"Số ID GAT có nhưng BERT không có:\", len(missing_in_bert))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "730594d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng ID BERT: 8014\n",
      "Số lượng ID GAT : 8006\n",
      " All Data: Số lượng không khớp! BERT=8014, GAT=8006\n",
      "KIỂM TRA PHẦN TỬ BỊ THIẾU:\n",
      "ID có trong BERT nhưng KHÔNG có trong GAT:\n",
      "['TOX28623', 'TOX24552', 'TOX24723', 'TOX24622', 'TOX31563', 'TOX24724', 'TOX7518', 'TOX28892']\n",
      "Không có ID nào trong GAT bị thiếu ở BERT\n",
      "Bỏ qua kiểm tra thứ tự vì số lượng không khớp\n"
     ]
    }
   ],
   "source": [
    "def check_alignment(bert_data, gat_data, split_name):\n",
    "    \"\"\"Kiểm tra xem mol_ids có khớp nhau không\"\"\"\n",
    "    bert_ids = bert_data['mol_id']  \n",
    "    gat_ids = gat_data['mol_ids']\n",
    "    \n",
    "    # Chuyển thành list thuần (phòng trường hợp tensor)\n",
    "    if not isinstance(bert_ids, list):\n",
    "        bert_ids = list(bert_ids)\n",
    "    if not isinstance(gat_ids, list):\n",
    "        gat_ids = list(gat_ids)\n",
    "    \n",
    "    print(f\"Số lượng ID BERT: {len(bert_ids)}\")\n",
    "    print(f\"Số lượng ID GAT : {len(gat_ids)}\")\n",
    "\n",
    "    # KTRA SỐ LƯỢNG\n",
    "\n",
    "    # So sánh\n",
    "    if len(bert_ids) != len(gat_ids):\n",
    "        print(f\" {split_name}: Số lượng không khớp! BERT={len(bert_ids)}, GAT={len(gat_ids)}\")\n",
    "    \n",
    "    #Tìm các ID có trong BERT nhưng không có trong GAT\n",
    "    missing_in_gat = set(bert_ids) - set(gat_ids)\n",
    "    missing_in_bert = set(gat_ids) - set(bert_ids)\n",
    "\n",
    "    print('KIỂM TRA PHẦN TỬ BỊ THIẾU:')\n",
    "\n",
    "    if len(missing_in_gat) == 0:\n",
    "        print(\"Không có ID nào trong BERT bị thiếu ở GAT\")\n",
    "    else:\n",
    "        print(\"ID có trong BERT nhưng KHÔNG có trong GAT:\")\n",
    "        print(list(missing_in_gat))\n",
    "\n",
    "    if len(missing_in_bert) == 0:\n",
    "        print(\"Không có ID nào trong GAT bị thiếu ở BERT\")\n",
    "    else:\n",
    "        print(\"ID có trong GAT nhưng KHÔNG có trong BERT:\")\n",
    "        print(list(missing_in_bert))\n",
    "\n",
    "    # Nếu số lượng khớp hoàn toàn => kiểm tra thứ tự\n",
    "    # Kiểm tra thứ tự\n",
    "    if len(bert_ids) == len(gat_ids):\n",
    "        print(\"\\nKIỂM TRA THỨ TỰ PHẦN TỬ:\")\n",
    "        same_order = all(b == g for b, g in zip(bert_ids, gat_ids))\n",
    "\n",
    "        if same_order:\n",
    "            print(\"THỨ TỰ GIỐNG NHAU!\")\n",
    "        else:\n",
    "            print(\"Thứ tự KHÔNG khớp!\")\n",
    "            print(\"5 phần tử đầu:\")\n",
    "            for i in range(5):\n",
    "                print(f\"  BERT[{i}] = {bert_ids[i]},  GAT[{i}] = {gat_ids[i]}\")\n",
    "    else:\n",
    "        print(\"Bỏ qua kiểm tra thứ tự vì số lượng không khớp\")\n",
    "\n",
    "# Check tất cả splits\n",
    "# train_match = check_alignment(bert_train, gat_train, \"Train\")\n",
    "# val_match = check_alignment(bert_val, gat_val, \"Val\")\n",
    "# test_match = check_alignment(bert_test, gat_test, \"Test\")\n",
    "all_match = check_alignment(bert_all, gat_all, \"All Data\")\n",
    "\n",
    "\n",
    "# output \n",
    "# số lượng k = nhau nên k thể align theo thứ tự "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9473bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_all['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1ef40be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT có 8014 mẫu\n",
      "GAT  có 8006 mẫu\n",
      "Trùng mol_id: 8006 mẫu\n"
     ]
    }
   ],
   "source": [
    "# đảm bảo bert gat cùng số mẫu \n",
    "# đúng thứ tự theo mol id \n",
    "def align_datasets(bert_data, gat_data):\n",
    "    \"\"\"Align BERT và GAT theo mol_id (không kiểm tra labels).\"\"\"\n",
    "\n",
    "    bert_ids = bert_data['mol_id']\n",
    "    gat_ids  = gat_data['mol_ids']\n",
    "\n",
    "    # Tạo dictionary để tìm index nhanh\n",
    "    bert_dict = {str(m): i for i, m in enumerate(bert_ids)}\n",
    "    gat_dict  = {str(m): i for i, m in enumerate(gat_ids)}\n",
    "\n",
    "    # Lấy phần giao của mol_id\n",
    "    common_ids = sorted(set(bert_dict.keys()) & set(gat_dict.keys()))\n",
    "\n",
    "    print(f\"BERT có {len(bert_ids)} mẫu\")\n",
    "    print(f\"GAT  có {len(gat_ids)} mẫu\")\n",
    "    print(f\"Trùng mol_id: {len(common_ids)} mẫu\")\n",
    "\n",
    "    bert_indices = [bert_dict[m] for m in common_ids]\n",
    "    gat_indices  = [gat_dict[m] for m in common_ids]\n",
    "\n",
    "    # Embeddings\n",
    "    bert_embs = bert_data[\"embeddings\"][bert_indices]\n",
    "    gat_embs  = gat_data[\"embeddings\"][gat_indices]\n",
    "\n",
    "    # Labels\n",
    "    bert_labels = bert_data[\"labels\"][bert_indices]\n",
    "    gat_labels  = gat_data[\"labels\"][gat_indices]\n",
    "\n",
    "    aligned_bert = {\n",
    "        \"embeddings\": bert_embs,\n",
    "        \"labels\": bert_labels,\n",
    "        \"mol_id\": common_ids\n",
    "    }\n",
    "\n",
    "    aligned_gat = {\n",
    "        \"embeddings\": gat_embs,\n",
    "        \"labels\": gat_labels,\n",
    "        \"mol_ids\": common_ids\n",
    "    }\n",
    "\n",
    "    return aligned_bert, aligned_gat\n",
    "\n",
    "\n",
    "# Align từng split\n",
    "\n",
    "all_bert_aligned, all_gat_aligned = align_datasets(bert_all, gat_all)\n",
    "# Tạo datasets\n",
    "\n",
    "\n",
    "# print(f\"\\n Datasets created:\")\n",
    "# print(f\"Train: {len(train_dataset)} samples\")\n",
    "# print(f\"Val: {len(val_dataset)} samples\")\n",
    "# print(f\"Test: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee6bda17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FusionDataset(Dataset):\n",
    "    def __init__(self, bert_data, gat_data):\n",
    "        # Embeddings\n",
    "        self.text_embs = bert_data['embeddings']\n",
    "        self.graph_embs = gat_data['embeddings']\n",
    "        \n",
    "        # Labels (lấy từ 1 trong 2, giả sử giống nhau)\n",
    "        self.labels = bert_data['labels']\n",
    "        \n",
    "        # Optional: mol_ids để track\n",
    "        self.mol_ids = bert_data['mol_id']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'text_emb': self.text_embs[idx],\n",
    "            'graph_emb': self.graph_embs[idx],\n",
    "            'label': self.labels[idx],\n",
    "            'mol_id': self.mol_ids[idx]\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b14fea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total aligned samples: 8006\n",
      "<class 'torch.Tensor'>\n",
      "len train index: 6404\n",
      "len val index: 801\n",
      "len test index: 801\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "N = len(all_bert_aligned[\"mol_id\"])\n",
    "print(\"Total aligned samples:\", N)\n",
    "indices = np.arange(N)\n",
    "\n",
    "print(type(all_bert_aligned[\"labels\"]))\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "val_idx, test_idx = train_test_split(test_idx, test_size=0.5, random_state=42)\n",
    "\n",
    "print('len train index:',len(train_idx))\n",
    "print('len val index:' , len(val_idx))\n",
    "print('len test index:', len(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c4dee0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Datasets created:\n",
      "Train: 6404 samples\n",
      "Val: 801 samples\n",
      "Test: 801 samples\n"
     ]
    }
   ],
   "source": [
    "def split_data(aligned_data, idx, mol_id):\n",
    "    return {\n",
    "        \"embeddings\": aligned_data[\"embeddings\"][idx],\n",
    "        \"labels\": aligned_data[\"labels\"][idx],\n",
    "        \"mol_id\": [aligned_data[mol_id][i] for i in idx]\n",
    "    }\n",
    "train_bert_aligned = split_data(all_bert_aligned, train_idx, \"mol_id\")\n",
    "val_bert_aligned = split_data(all_bert_aligned, val_idx, \"mol_id\")\n",
    "test_bert_aligned = split_data(all_bert_aligned, test_idx, \"mol_id\")\n",
    "\n",
    "train_dataset = FusionDataset(train_bert_aligned, split_data(all_gat_aligned, train_idx, \"mol_ids\"))\n",
    "val_dataset = FusionDataset(val_bert_aligned, split_data(all_gat_aligned, val_idx, \"mol_ids\"))\n",
    "test_dataset = FusionDataset(test_bert_aligned, split_data(all_gat_aligned, test_idx, \"mol_ids\"))\n",
    "print(f\"\\n Datasets created:\")\n",
    "print(f\"Train: {len(train_dataset)} samples\")\n",
    "print(f\"Val: {len(val_dataset)} samples\")\n",
    "print(f\"Test: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2106101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedFusion(nn.Module):\n",
    "    def __init__(self, \n",
    "                 dim_bert, \n",
    "                 dim_gat, \n",
    "                 common_dim=256, \n",
    "                 per_dim=True,\n",
    "                 ):\n",
    "        \n",
    "\n",
    "        super().__init__()\n",
    "        self.bert_to_common = nn.Linear(dim_bert, common_dim) #chiếu BERT sang không gian chung\n",
    "        self.gat_to_common  = nn.Linear(dim_gat, common_dim)\n",
    "        # Kích thước đầu vào của gate = concat(b,g) = 2 * common_dim\n",
    "        gate_in_dim = common_dim * 2\n",
    "        if per_dim:\n",
    "            #alpha cho từng chiều của vector\n",
    "            self.gate = nn.Sequential(\n",
    "                nn.Linear(gate_in_dim, common_dim), # tính alpha cho từng chiều\n",
    "                nn.Sigmoid() # đưa alpha về [0,1]\n",
    "            )\n",
    "        else:\n",
    "            # alpha là 1 giá trị chung cho cả vector\n",
    "            self.gate = nn.Sequential(\n",
    "                nn.Linear(gate_in_dim, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        self.per_dim = per_dim\n",
    "\n",
    "    def forward(self, bert_embedding, gat_embedding):\n",
    "        # bert_x: (batch, dim_bert)\n",
    "        b = torch.tanh(self.bert_to_common(bert_embedding))   # (batch, common_dim)\n",
    "        g = torch.tanh(self.gat_to_common(gat_embedding))     # (batch, common_dim)\n",
    "        # nối 2 vector trước khi vào gate  \n",
    "        concat_features = torch.cat([b, g], dim=1)           # (batch, 2*common_dim)\n",
    "        alpha = self.gate(concat_features)                   # (batch, common_dim) or (batch,1)\n",
    "        # Fusion: weighted sum\n",
    "        fused = alpha * b + (1.0 - alpha) * g   # broadcast nếu alpha scalar\n",
    "    \n",
    "\n",
    "        # trả về embedding cuối cùng sau train \n",
    "        return fused, alpha\n",
    "    \n",
    "class ToxicityModel(nn.Module):\n",
    "    def __init__(self, dim_bert, dim_gat, num_labels=12):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fusion = GatedFusion(dim_bert, dim_gat, common_dim=256, per_dim=True)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, bert_emb, gat_emb):\n",
    "        fused, alpha = self.fusion(bert_emb, gat_emb)\n",
    "        logits = self.classifier(fused)\n",
    "        return logits, alpha\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47d8b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "=== Configuration ===\n",
      "Text dim: 768\n",
      "Graph dim: 512\n",
      "Num labels (organs): 12\n",
      "=== Batch Debug ===\n",
      "text_emb: torch.Size([32, 768]), dtype: torch.float32\n",
      "graph_emb: torch.Size([32, 512]), dtype: torch.float32\n",
      "label: torch.Size([32, 12]), dtype: torch.float32\n",
      "label values: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Get dimensions\n",
    "sample_batch = next(iter(train_loader))\n",
    "text_dim = sample_batch['text_emb'].shape[1]  # 768\n",
    "graph_dim = sample_batch['graph_emb'].shape[1]  # 512\n",
    "num_labels = sample_batch['label'].shape[1]  # 12\n",
    "\n",
    "print(f\"\\n=== Configuration ===\")\n",
    "print(f\"Text dim: {text_dim}\")\n",
    "print(f\"Graph dim: {graph_dim}\")\n",
    "print(f\"Num labels (organs): {num_labels}\")\n",
    "\n",
    "\n",
    "# Initialize model (you can pass init_gate_pref to bias initial gate, and force_ratio to force global ratio)\n",
    "model = ToxicityModel(\n",
    "    dim_bert=text_dim,\n",
    "    dim_gat=graph_dim,\n",
    "    num_labels=num_labels\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# Chạy này trước khi train để kiểm tra\n",
    "batch = next(iter(train_loader))\n",
    "print(\"=== Batch Debug ===\")\n",
    "print(f\"text_emb: {batch['text_emb'].shape}, dtype: {batch['text_emb'].dtype}\")\n",
    "print(f\"graph_emb: {batch['graph_emb'].shape}, dtype: {batch['graph_emb'].dtype}\")\n",
    "print(f\"label: {batch['label'].shape}, dtype: {batch['label'].dtype}\")\n",
    "print(f\"label values: {batch['label'][:5]}\")  # First 5 labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d502292b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch  1 | Loss: 0.0537 | F1: 1.0000 | Acc: 1.0000 | BERT: 0.685 | GAT: 0.683 | Var: 0.0332 | α=0.030\n",
      "Epoch  2 | Loss: 0.0422 | F1: 1.0000 | Acc: 1.0000 | BERT: 0.664 | GAT: 0.707 | Var: 0.0294 | α=0.030\n",
      "Epoch  3 | Loss: 0.0345 | F1: 1.0000 | Acc: 1.0000 | BERT: 0.642 | GAT: 0.697 | Var: 0.0240 | α=0.030\n",
      "Epoch  4 | Loss: 0.0289 | F1: 1.0000 | Acc: 1.0000 | BERT: 0.615 | GAT: 0.682 | Var: 0.0204 | α=0.030\n",
      "Epoch  5 | Loss: 0.0258 | F1: 1.0000 | Acc: 1.0000 | BERT: 0.581 | GAT: 0.686 | Var: 0.0175 | α=0.030\n",
      "Epoch  6 | Loss: 0.0249 | F1: 1.0000 | Acc: 1.0000 | BERT: 0.575 | GAT: 0.671 | Var: 0.0145 | α=0.030\n",
      "Epoch  7 | Loss: 0.0222 | F1: 1.0000 | Acc: 1.0000 | BERT: 0.555 | GAT: 0.655 | Var: 0.0139 | α=0.030\n",
      "Epoch  8 | Loss: 0.0182 | F1: 1.0000 | Acc: 1.0000 | BERT: 0.565 | GAT: 0.660 | Var: 0.0124 | α=0.030\n",
      "Epoch  9 | Loss: 0.0176 | F1: 1.0000 | Acc: 1.0000 | BERT: 0.515 | GAT: 0.668 | Var: 0.0110 | α=0.030\n",
      "Epoch 10 | Loss: 0.0164 | F1: 1.0000 | Acc: 1.0000 | BERT: 0.539 | GAT: 0.672 | Var: 0.0107 | α=0.030\n",
      "Epoch 11 | Loss: 0.0157 | F1: 1.0000 | Acc: 1.0000 | BERT: 0.533 | GAT: 0.620 | Var: 0.0104 | α=0.030\n",
      "\n",
      "Early stopping at epoch 11\n",
      "\n",
      "=== Test Results ===\n",
      "Accuracy: 0.9988\n",
      "F1: 0.9984\n",
      "ROC-AUC: 1.0000\n",
      "BERT avg weight: 0.683\n",
      "GAT avg weight: 0.680\n",
      "Weight variance: 0.0329\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# ========== DataLoaders ==========\n",
    "# {'text_emb': Tensor[batch, 768], 'graph_emb': Tensor[batch, 512], 'label': Tensor[batch,12]}\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ========== Model ==========\n",
    "# model = GatedFusion + classifier, output multi-label [batch,12]\n",
    "model = model.to(device)\n",
    "\n",
    "# ========== Loss & Optimizer ==========\n",
    "all_labels = torch.cat([batch['label'] for batch in train_loader], dim=0)\n",
    "label_freq = all_labels.sum(dim=0)\n",
    "neg_freq = all_labels.size(0) - label_freq\n",
    "pos_weight = (neg_freq / (label_freq + 1e-6)).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# ========== Training/Evaluation Functions ==========\n",
    "def train_epoch(model, loader, optimizer, criterion, device, balance_alpha=0.0):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        text_emb = batch['text_emb'].to(device)\n",
    "        graph_emb = batch['graph_emb'].to(device)\n",
    "        labels   = batch['label'].to(device)  # [batch,12]\n",
    "\n",
    "        # Forward\n",
    "        logits, weights = model(text_emb, graph_emb)  # [batch,12], [batch,1,2]\n",
    "\n",
    "        # BCE loss multi-label\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "     \n",
    "        if balance_alpha > 0:\n",
    "            w = weights.squeeze(1)  # [batch,2]\n",
    "            target = torch.ones_like(w) * 0.5\n",
    "            balance_loss = ((w - target)**2).mean()\n",
    "            loss = loss + balance_alpha * balance_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate_any_toxic(model, loader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_logits, all_labels, all_weights = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            text_emb = batch['text_emb'].to(device)\n",
    "            graph_emb = batch['graph_emb'].to(device)\n",
    "            labels = batch['label'].to(device)  # [batch,12]\n",
    "\n",
    "            logits, weights = model(text_emb, graph_emb)\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_weights.append(weights.cpu())\n",
    "\n",
    "    logits = torch.cat(all_logits, dim=0)\n",
    "    labels = torch.cat(all_labels, dim=0)\n",
    "    weights = torch.cat(all_weights, dim=0)\n",
    "\n",
    "    # Any-toxic metrics\n",
    "    labels_any = (labels.sum(dim=1) > 0).float()\n",
    "    probs_any  = torch.sigmoid(logits).max(dim=1)[0]\n",
    "    preds_any  = (probs_any > threshold).float()\n",
    "\n",
    "    # Weight statistics\n",
    "    w = weights.squeeze(1)\n",
    "    bert_w = w[:,0]\n",
    "    gat_w  = w[:,1]\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(labels_any, preds_any),\n",
    "        'f1': f1_score(labels_any, preds_any),\n",
    "        'roc_auc': roc_auc_score(labels_any, probs_any),\n",
    "        'avg_bert_weight': bert_w.mean().item(),\n",
    "        'avg_gat_weight': gat_w.mean().item(),\n",
    "        'bert_std': bert_w.std().item(),\n",
    "        'gat_std': gat_w.std().item(),\n",
    "        'mean_variance': ((w - 0.5)**2).mean().item()\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# ========== Training Loop ==========\n",
    "best_val_f1 = 0\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "balance_alpha = 0.03\n",
    "min_variance_threshold = 0.001\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device, balance_alpha)\n",
    "    val_metrics = evaluate_any_toxic(model, val_loader, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:2d} | Loss: {train_loss:.4f} | \"\n",
    "          f\"F1: {val_metrics['f1']:.4f} | Acc: {val_metrics['accuracy']:.4f} | \"\n",
    "          f\"BERT: {val_metrics['avg_bert_weight']:.3f} | GAT: {val_metrics['avg_gat_weight']:.3f} | \"\n",
    "          f\"Var: {val_metrics['mean_variance']:.4f} | α={balance_alpha:.3f}\")\n",
    "\n",
    "    \n",
    "    if val_metrics['mean_variance'] < min_variance_threshold and epoch > 5:\n",
    "        balance_alpha = min(balance_alpha + 0.01, 0.05)\n",
    "        print(f\"  Variance too low! Increasing α to {balance_alpha:.3f}\")\n",
    "\n",
    "\n",
    "    if val_metrics['f1'] > best_val_f1:\n",
    "        best_val_f1 = val_metrics['f1']\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_metrics': val_metrics,\n",
    "        }, 'best_any_toxic_model.pt')\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# ========== Test ==========\n",
    "checkpoint = torch.load('best_any_toxic_model.pt', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "test_metrics = evaluate_any_toxic(model, test_loader, device)\n",
    "\n",
    "print(\"\\n=== Test Results ===\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1: {test_metrics['f1']:.4f}\")\n",
    "print(f\"ROC-AUC: {test_metrics['roc_auc']:.4f}\")\n",
    "print(f\"BERT avg weight: {test_metrics['avg_bert_weight']:.3f}\")\n",
    "print(f\"GAT avg weight: {test_metrics['avg_gat_weight']:.3f}\")\n",
    "print(f\"Weight variance: {test_metrics['mean_variance']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0d570d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BERT contribution: 0.685248613357544\n",
      " GAT contribution : 0.6830386519432068\n",
      "Variance: tensor([0.0047, 0.0034, 0.0013, 0.0024, 0.0028, 0.0039, 0.0035, 0.0010, 0.0024,\n",
      "        0.0020, 0.0016, 0.0025, 0.0060, 0.0042, 0.0015, 0.0011, 0.0012, 0.0020,\n",
      "        0.0036, 0.0010, 0.0015, 0.0024, 0.0026, 0.0019, 0.0035, 0.0019, 0.0024,\n",
      "        0.0028, 0.0031, 0.0017, 0.0029, 0.0044, 0.0015, 0.0017, 0.0015, 0.0030,\n",
      "        0.0027, 0.0022, 0.0023, 0.0017, 0.0021, 0.0034, 0.0022, 0.0041, 0.0021,\n",
      "        0.0020, 0.0017, 0.0017, 0.0028, 0.0030, 0.0043, 0.0032, 0.0027, 0.0012,\n",
      "        0.0038, 0.0023, 0.0017, 0.0040, 0.0029, 0.0022, 0.0007, 0.0018, 0.0030,\n",
      "        0.0022, 0.0036, 0.0012, 0.0037, 0.0067, 0.0034, 0.0017, 0.0017, 0.0021,\n",
      "        0.0028, 0.0016, 0.0020, 0.0013, 0.0018, 0.0028, 0.0032, 0.0036, 0.0033,\n",
      "        0.0021, 0.0048, 0.0074, 0.0033, 0.0035, 0.0024, 0.0062, 0.0017, 0.0035,\n",
      "        0.0022, 0.0013, 0.0024, 0.0031, 0.0023, 0.0019, 0.0033, 0.0011, 0.0029,\n",
      "        0.0022, 0.0030, 0.0022, 0.0019, 0.0016, 0.0020, 0.0025, 0.0028, 0.0046,\n",
      "        0.0019, 0.0014, 0.0038, 0.0020, 0.0014, 0.0023, 0.0051, 0.0034, 0.0013,\n",
      "        0.0032, 0.0040, 0.0011, 0.0018, 0.0019, 0.0023, 0.0022, 0.0047, 0.0032,\n",
      "        0.0039, 0.0035, 0.0020, 0.0015, 0.0016, 0.0016, 0.0020, 0.0016, 0.0045,\n",
      "        0.0034, 0.0019, 0.0021, 0.0040, 0.0022, 0.0019, 0.0046, 0.0016, 0.0009,\n",
      "        0.0039, 0.0032, 0.0017, 0.0027, 0.0020, 0.0014, 0.0027, 0.0024, 0.0021,\n",
      "        0.0037, 0.0026, 0.0034, 0.0021, 0.0028, 0.0020, 0.0017, 0.0023, 0.0030,\n",
      "        0.0031, 0.0031, 0.0039, 0.0025, 0.0053, 0.0027, 0.0027, 0.0028, 0.0024,\n",
      "        0.0017, 0.0011, 0.0046, 0.0027, 0.0026, 0.0022, 0.0053, 0.0011, 0.0028,\n",
      "        0.0041, 0.0016, 0.0011, 0.0032, 0.0035, 0.0031, 0.0030, 0.0038, 0.0027,\n",
      "        0.0035, 0.0026, 0.0034, 0.0024, 0.0017, 0.0033, 0.0060, 0.0016, 0.0026,\n",
      "        0.0020, 0.0019, 0.0024, 0.0009, 0.0048, 0.0031, 0.0039, 0.0029, 0.0027,\n",
      "        0.0022, 0.0043, 0.0016, 0.0016, 0.0044, 0.0017, 0.0009, 0.0038, 0.0014,\n",
      "        0.0049, 0.0016, 0.0026, 0.0024, 0.0022, 0.0032, 0.0027, 0.0013, 0.0048,\n",
      "        0.0017, 0.0047, 0.0022, 0.0020, 0.0019, 0.0026, 0.0023, 0.0014, 0.0075,\n",
      "        0.0020, 0.0032, 0.0032, 0.0012, 0.0013, 0.0036, 0.0057, 0.0020, 0.0046,\n",
      "        0.0013, 0.0024, 0.0020, 0.0028, 0.0038, 0.0018, 0.0028, 0.0025, 0.0028,\n",
      "        0.0027, 0.0021, 0.0026, 0.0026])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_weights = []\n",
    "\n",
    "for batch in val_loader:\n",
    "    text_emb = batch['text_emb'].to(device)\n",
    "    graph_emb = batch['graph_emb'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, attn = model(text_emb, graph_emb)\n",
    "    \n",
    "    # attn shape = [batch, 1, 2]  => squeeze thành [batch, 2]\n",
    "    all_weights.append(attn.squeeze(1).cpu())\n",
    "\n",
    "all_weights = torch.cat(all_weights, dim=0)\n",
    "\n",
    "bert_contrib = all_weights[:, 0].mean().item()\n",
    "gat_contrib  = all_weights[:, 1].mean().item()\n",
    "\n",
    "print(\" BERT contribution:\", bert_contrib)\n",
    "print(\" GAT contribution :\", gat_contrib)\n",
    "print(\"Variance:\", all_weights.var(dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b84edfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự đoán SMILE toxic\n",
      "Probability: 0.997\n"
     ]
    }
   ],
   "source": [
    "def predict_from_embeddings(text_emb, graph_emb, model, device):\n",
    "    model.eval()\n",
    "    text_emb = text_emb.to(device)\n",
    "    graph_emb = graph_emb.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits, _ = model(text_emb, graph_emb)\n",
    "        any_logits = logits.max(dim=1)[0]       # any-toxic\n",
    "        prob = torch.sigmoid(any_logits)\n",
    "        pred = (prob > 0.5).float()\n",
    "    return pred.item(), prob.item()\n",
    "\n",
    "\n",
    "idx = 10  # index của molecule\n",
    "\n",
    "# Chuyển numpy -> tensor\n",
    "text_emb = torch.tensor(bert_all['embeddings'][idx], dtype=torch.float32).unsqueeze(0)  # [1, 768]\n",
    "graph_emb = gat_all['embeddings'][idx].detach().clone().unsqueeze(0)\n",
    "\n",
    "pred, prob = predict_from_embeddings(text_emb, graph_emb, model, device)\n",
    "if pred == 1:\n",
    "    print('Dự đoán SMILE toxic')\n",
    "elif pred == 0:\n",
    "    print('Dự đoán SMILE non toxic')\n",
    "\n",
    "print(f\"Probability: {prob:.3f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HD_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
